{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D,BatchNormalization, Flatten\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.image  as mpimg\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0_path = '../data/gan/0/gan_generated_engiin_X_train.csv'\n",
    "train1_path = '../data/gan/1/gan_generated_X_train.csv'\n",
    "test0_path = '../data/gan/0/gan_generated_engiin_X_test.csv'\n",
    "test1_path = '../data/gan/1/gan_generated_X_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train0 = pd.read_csv(train0_path)\n",
    "df_train0['y'] = 0\n",
    "df_train1 = pd.read_csv(train1_path)\n",
    "df_train1['y'] = 1\n",
    "df_test0 = pd.read_csv(test0_path)\n",
    "df_test0['y'] = 0\n",
    "df_test1 = pd.read_csv(test1_path)\n",
    "df_test1['y'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_train0, df_train1], ignore_index=True)\n",
    "train_df = shuffle(combined_df, random_state=42)\n",
    "combined_df = pd.concat([df_test0, df_test1], ignore_index=True)\n",
    "test_df = shuffle(combined_df, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['y']\n",
    "x_train = train_df.drop(columns = ['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\home\\anaconda3\\envs\\dxcup\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert '63' to a shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m     31\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m63\u001b[39m  \u001b[38;5;66;03m# Shape for CNN\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 6\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(input_shape):\n\u001b[0;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      8\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\home\\anaconda3\\envs\\dxcup\\Lib\\site-packages\\keras\\src\\models\\sequential.py:88\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer, rebuild)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_input_shape_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(\u001b[43mInputLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_shape_arg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# If we are passed a Keras tensor created by keras.Input(), we\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# extract the input layer from its keras history and use that.\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_history\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\home\\anaconda3\\envs\\dxcup\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:47\u001b[0m, in \u001b[0;36mInputLayer.__init__\u001b[1;34m(self, shape, batch_size, dtype, sparse, batch_shape, input_tensor, optional, name, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must pass a `shape` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m (batch_size,) \u001b[38;5;241m+\u001b[39m shape\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_shape \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mstandardize_shape(batch_shape)\n",
      "File \u001b[1;32mc:\\Users\\home\\anaconda3\\envs\\dxcup\\Lib\\site-packages\\keras\\src\\backend\\common\\variables.py:515\u001b[0m, in \u001b[0;36mstandardize_shape\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUndefined shapes are not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(shape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to a shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mbackend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, tf\u001b[38;5;241m.\u001b[39mTensorShape):\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;66;03m# `tf.TensorShape` may contain `Dimension` objects.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m         \u001b[38;5;66;03m# We need to convert the items in it to either int or `None`\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert '63' to a shape."
     ]
    }
   ],
   "source": [
    "num_labels = 2\n",
    "filter_size = 3\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=filter_size,input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    # model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_labels, activation='softmax')) \n",
    "        \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = 63  # Shape for CNN\n",
    "model = create_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(8, 63), dtype=float32). Expected shape (None, 15, 157, 1), but input has incompatible shape (8, 63)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(8, 63), dtype=float32)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m      2\u001b[0m num_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\home\\anaconda3\\envs\\dxcup\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\home\\anaconda3\\envs\\dxcup\\Lib\\site-packages\\keras\\src\\models\\functional.py:264\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    263\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(8, 63), dtype=float32). Expected shape (None, 15, 157, 1), but input has incompatible shape (8, 63)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(8, 63), dtype=float32)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "num_batch_size = 8\n",
    "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-375.99005</td>\n",
       "      <td>118.480576</td>\n",
       "      <td>-20.414503</td>\n",
       "      <td>-1.954139</td>\n",
       "      <td>-24.048023</td>\n",
       "      <td>12.559255</td>\n",
       "      <td>-10.250502</td>\n",
       "      <td>-11.466636</td>\n",
       "      <td>-0.062914</td>\n",
       "      <td>9.698340</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>-375.53497</td>\n",
       "      <td>118.591736</td>\n",
       "      <td>-20.677240</td>\n",
       "      <td>-1.987650</td>\n",
       "      <td>-24.195997</td>\n",
       "      <td>18.912935</td>\n",
       "      <td>-11.115066</td>\n",
       "      <td>-12.095480</td>\n",
       "      <td>-2.589219</td>\n",
       "      <td>9.695402</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696117</td>\n",
       "      <td>0.268440</td>\n",
       "      <td>0.278559</td>\n",
       "      <td>8.756587</td>\n",
       "      <td>8.373384</td>\n",
       "      <td>14.083437</td>\n",
       "      <td>12.592300</td>\n",
       "      <td>15.373389</td>\n",
       "      <td>20.875595</td>\n",
       "      <td>16.447632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>-375.40353</td>\n",
       "      <td>118.543465</td>\n",
       "      <td>-20.658283</td>\n",
       "      <td>-1.982052</td>\n",
       "      <td>-24.190529</td>\n",
       "      <td>13.697533</td>\n",
       "      <td>-11.125987</td>\n",
       "      <td>-12.040660</td>\n",
       "      <td>-3.341849</td>\n",
       "      <td>9.710567</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>-381.11038</td>\n",
       "      <td>118.096450</td>\n",
       "      <td>-20.512941</td>\n",
       "      <td>-1.910100</td>\n",
       "      <td>-24.118433</td>\n",
       "      <td>10.749858</td>\n",
       "      <td>-7.443826</td>\n",
       "      <td>-11.819968</td>\n",
       "      <td>-3.549537</td>\n",
       "      <td>9.655209</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>-376.01505</td>\n",
       "      <td>118.542030</td>\n",
       "      <td>-20.502392</td>\n",
       "      <td>-1.948830</td>\n",
       "      <td>-24.144762</td>\n",
       "      <td>22.401407</td>\n",
       "      <td>-11.047319</td>\n",
       "      <td>-12.046876</td>\n",
       "      <td>-3.562387</td>\n",
       "      <td>9.642476</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699765</td>\n",
       "      <td>0.266287</td>\n",
       "      <td>0.275081</td>\n",
       "      <td>8.855160</td>\n",
       "      <td>8.339451</td>\n",
       "      <td>14.095439</td>\n",
       "      <td>12.530910</td>\n",
       "      <td>15.373094</td>\n",
       "      <td>20.889585</td>\n",
       "      <td>16.431921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-375.10770</td>\n",
       "      <td>118.543030</td>\n",
       "      <td>-20.229042</td>\n",
       "      <td>-1.979926</td>\n",
       "      <td>-24.136505</td>\n",
       "      <td>10.597741</td>\n",
       "      <td>-10.610054</td>\n",
       "      <td>-11.632885</td>\n",
       "      <td>-0.223923</td>\n",
       "      <td>9.666960</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697037</td>\n",
       "      <td>0.269486</td>\n",
       "      <td>0.280505</td>\n",
       "      <td>8.797415</td>\n",
       "      <td>8.369531</td>\n",
       "      <td>14.052298</td>\n",
       "      <td>12.721064</td>\n",
       "      <td>15.370816</td>\n",
       "      <td>20.848078</td>\n",
       "      <td>16.749083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699435</td>\n",
       "      <td>0.265500</td>\n",
       "      <td>0.274695</td>\n",
       "      <td>8.518004</td>\n",
       "      <td>8.327853</td>\n",
       "      <td>14.101267</td>\n",
       "      <td>12.528736</td>\n",
       "      <td>15.368539</td>\n",
       "      <td>20.893137</td>\n",
       "      <td>16.406221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mfcc_1      mfcc_2     mfcc_3    mfcc_4     mfcc_5     mfcc_6  \\\n",
       "206  -375.99005  118.480576 -20.414503 -1.954139 -24.048023  12.559255   \n",
       "607  -375.53497  118.591736 -20.677240 -1.987650 -24.195997  18.912935   \n",
       "1304        NaN         NaN        NaN       NaN        NaN        NaN   \n",
       "858  -375.40353  118.543465 -20.658283 -1.982052 -24.190529  13.697533   \n",
       "519  -381.11038  118.096450 -20.512941 -1.910100 -24.118433  10.749858   \n",
       "...         ...         ...        ...       ...        ...        ...   \n",
       "806  -376.01505  118.542030 -20.502392 -1.948830 -24.144762  22.401407   \n",
       "1199        NaN         NaN        NaN       NaN        NaN        NaN   \n",
       "452  -375.10770  118.543030 -20.229042 -1.979926 -24.136505  10.597741   \n",
       "1156        NaN         NaN        NaN       NaN        NaN        NaN   \n",
       "1088        NaN         NaN        NaN       NaN        NaN        NaN   \n",
       "\n",
       "         mfcc_7     mfcc_8    mfcc_9   mfcc_10  ...        24        25  \\\n",
       "206  -10.250502 -11.466636 -0.062914  9.698340  ...       NaN       NaN   \n",
       "607  -11.115066 -12.095480 -2.589219  9.695402  ...       NaN       NaN   \n",
       "1304        NaN        NaN       NaN       NaN  ...  0.696117  0.268440   \n",
       "858  -11.125987 -12.040660 -3.341849  9.710567  ...       NaN       NaN   \n",
       "519   -7.443826 -11.819968 -3.549537  9.655209  ...       NaN       NaN   \n",
       "...         ...        ...       ...       ...  ...       ...       ...   \n",
       "806  -11.047319 -12.046876 -3.562387  9.642476  ...       NaN       NaN   \n",
       "1199        NaN        NaN       NaN       NaN  ...  0.699765  0.266287   \n",
       "452  -10.610054 -11.632885 -0.223923  9.666960  ...       NaN       NaN   \n",
       "1156        NaN        NaN       NaN       NaN  ...  0.697037  0.269486   \n",
       "1088        NaN        NaN       NaN       NaN  ...  0.699435  0.265500   \n",
       "\n",
       "            26        27        28         29         30         31  \\\n",
       "206        NaN       NaN       NaN        NaN        NaN        NaN   \n",
       "607        NaN       NaN       NaN        NaN        NaN        NaN   \n",
       "1304  0.278559  8.756587  8.373384  14.083437  12.592300  15.373389   \n",
       "858        NaN       NaN       NaN        NaN        NaN        NaN   \n",
       "519        NaN       NaN       NaN        NaN        NaN        NaN   \n",
       "...        ...       ...       ...        ...        ...        ...   \n",
       "806        NaN       NaN       NaN        NaN        NaN        NaN   \n",
       "1199  0.275081  8.855160  8.339451  14.095439  12.530910  15.373094   \n",
       "452        NaN       NaN       NaN        NaN        NaN        NaN   \n",
       "1156  0.280505  8.797415  8.369531  14.052298  12.721064  15.370816   \n",
       "1088  0.274695  8.518004  8.327853  14.101267  12.528736  15.368539   \n",
       "\n",
       "             32      label  \n",
       "206         NaN        NaN  \n",
       "607         NaN        NaN  \n",
       "1304  20.875595  16.447632  \n",
       "858         NaN        NaN  \n",
       "519         NaN        NaN  \n",
       "...         ...        ...  \n",
       "806         NaN        NaN  \n",
       "1199  20.889585  16.431921  \n",
       "452         NaN        NaN  \n",
       "1156  20.848078  16.749083  \n",
       "1088  20.893137  16.406221  \n",
       "\n",
       "[1200 rows x 63 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(audio_file, mode):\n",
    "    # we want to resample audio to 16 kHz\n",
    "    sr_new = 16000 # 16kHz sample rate\n",
    "    x, sr = librosa.load(audio_file, sr=sr_new)\n",
    "\n",
    "    # padding sound \n",
    "    # because duration of sound is dominantly 20 s and all of sample rate is 22050\n",
    "    # we want to pad or truncated sound which is below or above 20 s respectively\n",
    "    max_len = 5 * sr_new  # length of sound array = time x sample rate\n",
    "    if x.shape[0] < max_len:\n",
    "      # padding with zero\n",
    "      pad_width = max_len - x.shape[0]\n",
    "      x = np.pad(x, (0, pad_width))\n",
    "    elif x.shape[0] > max_len:\n",
    "      # truncated\n",
    "      x = x[:max_len]\n",
    "    \n",
    "    if mode == 'mfcc':\n",
    "      feature = librosa.feature.mfcc(y=x, sr=sr_new)\n",
    "    \n",
    "    elif mode == 'log_mel':\n",
    "      feature = librosa.feature.melspectrogram(y=x, sr=sr_new, n_mels=128, fmax=8000)\n",
    "      feature = librosa.power_to_db(feature, ref=np.max)\n",
    "    \n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_labels = []\n",
    "orig_preprocessed_data = []\n",
    "folder_path = \"data/orig/healthy/audiowav\"\n",
    "# folder_path = \"data/breath/0\"\n",
    "for filename in os.listdir(folder_path):\n",
    "    orig_labels.append(0)\n",
    "    data = preprocessing(os.path.join(folder_path, filename), mode = 'mfcc')\n",
    "    orig_preprocessed_data.append(data)\n",
    "folder_path = \"data/data\"\n",
    "# folder_path = \"data/breath/1\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    orig_labels.append(1)\n",
    "    data = preprocessing(os.path.join(folder_path, filename), mode = 'mfcc')\n",
    "    orig_preprocessed_data.append(data)\n",
    "orig_preprocessed_data = np.array(orig_preprocessed_data)\n",
    "orig_labels = np.array(orig_labels)\n",
    "encoder = LabelEncoder()\n",
    "orig_labels = to_categorical(encoder.fit_transform(orig_labels),num_classes=2) \n",
    "unique_values, counts = np.unique(orig_labels, return_counts=True)\n",
    "orig_preprocessed_data = orig_preprocessed_data.reshape((-1, 20, 157, 1))\n",
    "# Display unique values and their counts\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value: {value}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(orig_preprocessed_data, orig_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 20\n",
    "num_columns = 157\n",
    "num_channels = 1\n",
    "\n",
    "\n",
    "num_labels = 2\n",
    "filter_size = 2\n",
    "\n",
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=filter_size,input_shape=input_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(filters=32, kernel_size=filter_size, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=filter_size, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_labels, activation='softmax')) \n",
    "        \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "input_shape = (num_rows, num_columns, num_channels)  # Shape for CNN\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Construct model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_batch_size = 64\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='kaggle_only_{epoch:02d}.keras',\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1)\n",
    "]\n",
    "start = datetime.now()\n",
    "\n",
    "history = model.fit(preprocessed_data, oh_labels, batch_size=num_batch_size, epochs=num_epochs, callbacks=callbacks, verbose=1, validation_split=0.2)\n",
    "\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Loss\", \"Validation Loss\"])\n",
    "\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred_labels = pred.argmax(axis=1)  \n",
    "true_labels = y_test.argmax(axis=1)  # Assuming test_labels is one-hot encoded\n",
    "\n",
    "# Calculate the metrics\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "f1 = f1_score(true_labels, pred_labels)\n",
    "precision = precision_score(true_labels, pred_labels)\n",
    "recall = recall_score(true_labels, pred_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "conf_matrix = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "# Display the confusion matrix\n",
    "ConfusionMatrixDisplay(conf_matrix).plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dxcup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
