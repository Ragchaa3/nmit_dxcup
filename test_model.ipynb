{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(audio_file, mode):\n",
    "    # we want to resample audio to 16 kHz\n",
    "    sr_new = 16000 # 16kHz sample rate\n",
    "    x, sr = librosa.load(audio_file, sr=sr_new)\n",
    "    print(x.shape)\n",
    "    print(x)\n",
    "    # for i in range(100):\n",
    "    #   print(f\"{x[i]:.8f}\")\n",
    "    # padding sound \n",
    "    # because duration of sound is dominantly 20 s and all of sample rate is 22050\n",
    "    # we want to pad or truncated sound which is below or above 20 s respectively\n",
    "    max_len = 5 * sr_new  # length of sound array = time x sample rate\n",
    "    print(x.shape)\n",
    "    if x.shape[0] < max_len:\n",
    "      # padding with zero\n",
    "      pad_width = max_len - x.shape[0]\n",
    "      x = np.pad(x, (0, pad_width))\n",
    "    elif x.shape[0] > max_len:\n",
    "      # truncated\n",
    "      x = x[:max_len]\n",
    "    print(x.shape)\n",
    "    # print(x==normalized_data)\n",
    "    if mode == 'mfcc':\n",
    "      feature = librosa.feature.mfcc(y=x, sr=sr_new)\n",
    "    print(len(feature))\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved Keras model\n",
    "model = load_model(\"code/my_model.h5\")\n",
    "\n",
    "# # Convert to TensorFlow Lite format\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the model as a .tflite file\n",
    "# with open(\"model.tflite\", \"wb\") as f:\n",
    "#     f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180885,)\n",
      "[ 8.9523628e-06 -6.6128032e-06 -1.5109366e-05 ...  0.0000000e+00\n",
      " -3.6379788e-11 -2.9103830e-11]\n",
      "(180885,)\n",
      "(80000,)\n",
      "20\n",
      "(20, 157)\n"
     ]
    }
   ],
   "source": [
    "data = preprocessing(\"data\\\\orig\\\\1\\\\New Recording 13 [breath only].wav\", mode = 'mfcc')\n",
    "print(data.shape)\n",
    "# data = data.reshape((-1, 20, 157, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\AppData\\Local\\Temp\\ipykernel_1288\\1600509492.py:3: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sr, pcm_data = wavfile.read(\"data\\\\orig\\\\1\\\\New Recording 13 [breath only].wav\")\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "import wave\n",
    "sr, pcm_data = wavfile.read(\"data\\\\orig\\\\1\\\\New Recording 13 [breath only].wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\home\\AppData\\Local\\Temp\\ipykernel_1288\\3987412722.py:1: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sr, pcm_data_from_wavfile = wavfile.read(\"data\\\\orig\\\\1\\\\New Recording 13 [breath only].wav\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCM Data Length from wavfile.read(): 542655\n",
      "Shape from wavfile.read(): (542655, 2)\n",
      "542655\n",
      "2170620\n",
      "1085310\n",
      "PCM Data Length from raw bytes: 542655\n",
      "Shape from raw bytes: (542655, 2)\n",
      "542655\n",
      "542655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180885, 2)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr, pcm_data_from_wavfile = wavfile.read(\"data\\\\orig\\\\1\\\\New Recording 13 [breath only].wav\")\n",
    "print(f\"PCM Data Length from wavfile.read(): {len(pcm_data_from_wavfile)}\")\n",
    "print(f\"Shape from wavfile.read(): {pcm_data_from_wavfile.shape}\")\n",
    "\n",
    "# Manually reading the raw bytes from the WAV file using wave.open()\n",
    "with wave.open(\"data\\\\orig\\\\1\\\\New Recording 13 [breath only].wav\", \"rb\") as wav_file:\n",
    "    # Get the sample rate, number of channels, and sample width (bit depth)\n",
    "    sr = wav_file.getframerate()    # Sample rate (Hz)\n",
    "    num_channels = wav_file.getnchannels()  # Number of channels (1 for mono, 2 for stereo)\n",
    "    sampwidth = wav_file.getsampwidth()  # Bytes per sample (e.g., 2 for 16-bit, 4 for 32-bit)\n",
    "    num_frames = wav_file.getnframes()  # Number of frames in the audio\n",
    "    # Read the PCM data (raw bytes) from the WAV file\n",
    "    # print(wav_file._sampwidth != 1)\n",
    "    raw_pcm_data = wav_file.readframes(num_frames)\n",
    "# raw_pcm_data=raw_pcm_data[:960000]\n",
    "print(num_frames)\n",
    "print(len(raw_pcm_data))\n",
    "# Convert raw bytes to a numpy array based on the sample width\n",
    "if sampwidth == 2:  # 16-bit PCM (2 bytes per sample)\n",
    "    pcm_data_from_raw = np.frombuffer(raw_pcm_data, dtype=np.int16)\n",
    "print(len(pcm_data_from_raw))\n",
    "# Reshape the PCM data if stereo (2 channels)\n",
    "if num_channels == 2:\n",
    "    pcm_data_from_raw = pcm_data_from_raw.reshape(-1, 2)  # Shape it to (num_samples, 2)\n",
    "\n",
    "print(f\"PCM Data Length from raw bytes: {len(pcm_data_from_raw)}\")\n",
    "print(f\"Shape from raw bytes: {pcm_data_from_raw.shape}\")\n",
    "sr_orig = 48000  # Original sample rate (e.g., 44.1kHz)\n",
    "sr_new = 16000   # Target sample rate (e.g., 16kHz)\n",
    "\n",
    "resample_ratio = sr_new / sr_orig\n",
    "print(len(pcm_data_from_wavfile))\n",
    "print(len(pcm_data_from_raw))\n",
    "# Resample the data\n",
    "new_length = int(len(pcm_data_from_raw) * resample_ratio)\n",
    "resampled_data = scipy.signal.resample(pcm_data_from_raw, new_length)\n",
    "normalized_data = resampled_data.astype(np.float32) / 32768.0\n",
    "# print(new_length)\n",
    "normalized_data.shape\n",
    "# Check if the length and shape match\n",
    "# assert pcm_data_from_wavfile.shape == pcm_data_from_raw.shape, \"Shapes do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240000.0"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "80000/resample_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2170726\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "def read_wav_bytes(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        # Read the first 44 bytes of the WAV file header\n",
    "        header = file.read(44)\n",
    "        \n",
    "        # Unpack the header information\n",
    "        (chunk_id, chunk_size, format, subchunk1_id, subchunk1_size, audio_format, \n",
    "         num_channels, sample_rate, byte_rate, block_align, bits_per_sample, \n",
    "         subchunk2_id, subchunk2_size) = struct.unpack('<4sI4s4sIHHIIHH4sI', header)\n",
    "        \n",
    "        # Validate the header\n",
    "        assert chunk_id == b'RIFF'\n",
    "        assert format == b'WAVE'\n",
    "        assert subchunk1_id == b'fmt '\n",
    "        assert subchunk2_id == b'data'\n",
    "        \n",
    "        # Read the PCM data starting at the offset of the data subchunk\n",
    "        pcm_data = file.read()\n",
    "        \n",
    "        return pcm_data\n",
    "\n",
    "pcm_bytes = read_wav_bytes(\"data\\\\orig\\\\1\\\\New Recording 13 [breath only].wav\")\n",
    "print(len(pcm_bytes))  # Print the length of the PCM data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "16\n",
      "Total PCM Data Length: 2170726 bytes\n",
      "Framesize (bytes per frame): 32\n",
      "Total Frames: 67835\n",
      "PCM Data Length from raw bytes: 542680\n",
      "Shape from raw bytes: (542680, 2)\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "# Read the raw bytes from the WAV file\n",
    "with open(\"data\\\\orig\\\\1\\\\New Recording 13 [breath only].wav\", \"rb\") as file:\n",
    "    raw_bytes = file.read()\n",
    "\n",
    "# Extract metadata from the WAV header\n",
    "HEADER_SIZE = 44  # Standard WAV header size\n",
    "\n",
    "# Extract relevant header information\n",
    "riff = raw_bytes[0:4]  # Should be 'RIFF'\n",
    "file_size = struct.unpack('<I', raw_bytes[4:8])[0]  # Total file size\n",
    "wave1 = raw_bytes[8:12]  # 'WAVE'\n",
    "fmt = raw_bytes[12:16]  # 'fmt '\n",
    "fmt_chunk_size = struct.unpack('<I', raw_bytes[16:20])[0]\n",
    "audio_format = struct.unpack('<H', raw_bytes[20:22])[0]  # PCM is 1\n",
    "num_channels = struct.unpack('<H', raw_bytes[22:24])[0]\n",
    "sr = struct.unpack('<I', raw_bytes[24:28])[0]  # Sample rate (Hz)\n",
    "byte_rate = struct.unpack('<I', raw_bytes[28:32])[0]\n",
    "block_align = struct.unpack('<H', raw_bytes[32:34])[0]\n",
    "sampwidth = struct.unpack('<H', raw_bytes[34:36])[0]  # Bits per sample (16-bit = 2 bytes)\n",
    "\n",
    "# PCM data starts after the header\n",
    "pcm_data = raw_bytes[HEADER_SIZE:]\n",
    "for i in range(12):\n",
    "    if(pcm_data[i]!=raw_pcm_data[i+1]):\n",
    "        print(\"here\")\n",
    "\n",
    "# Calculate framesize (bytes per frame)\n",
    "framesize = sampwidth * num_channels\n",
    "\n",
    "# Calculate the total number of frames\n",
    "total_frames = len(pcm_data) // framesize\n",
    "\n",
    "# Output the results\n",
    "print(fmt_chunk_size)\n",
    "print(f\"Total PCM Data Length: {len(pcm_data)} bytes\")\n",
    "print(f\"Framesize (bytes per frame): {framesize}\")\n",
    "print(f\"Total Frames: {total_frames}\")\n",
    "\n",
    "def readframes(nframes):\n",
    "    start_index = 0\n",
    "    # Read raw PCM data for nframes\n",
    "    end_index = start_index + nframes * framesize\n",
    "    data = pcm_data[start_index:end_index]\n",
    "    return data\n",
    "\n",
    "# Example: Read the first 1000 frames\n",
    "nframes = total_frames\n",
    "raw_data = readframes(nframes)\n",
    "\n",
    "# Convert the raw byte data to a numpy array based on sample width (bit depth)\n",
    "if sampwidth == 16:  # 16-bit PCM (2 bytes per sample)\n",
    "    pcm_data_from_raw = np.frombuffer(raw_data, dtype=np.int16)\n",
    "elif sampwidth == 4:  # 32-bit PCM (4 bytes per sample)\n",
    "    pcm_data_from_raw = np.frombuffer(raw_data, dtype=np.int32)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported sample width: {sampwidth}\")\n",
    "\n",
    "# Reshape the PCM data if stereo (2 channels)\n",
    "if num_channels == 2:\n",
    "    pcm_data_from_raw = pcm_data_from_raw.reshape(-1, 2)  # Shape it to (num_samples, 2)\n",
    "\n",
    "# Output the results\n",
    "print(f\"PCM Data Length from raw bytes: {len(pcm_data_from_raw)}\")\n",
    "print(f\"Shape from raw bytes: {pcm_data_from_raw.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2107026 - 1085310*2\n",
    "1085363 -542655*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import scipy.signal\n",
    "\n",
    "# Define original and target sample rates\n",
    "sr_orig = 48000  # Original sample rate (e.g., 44.1kHz)\n",
    "sr_new = 16000   # Target sample rate (e.g., 16kHz)\n",
    "\n",
    "# Compute resampling ratio\n",
    "resample_ratio = sr_new / sr_orig\n",
    "\n",
    "# Resample the data\n",
    "new_length = int(len(pcm_data_from_wavfile) * resample_ratio)\n",
    "resampled_data = scipy.signal.resample(pcm_data_from_wavfile, new_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180885"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data = resampled_data.astype(np.float32) / 32768.0\n",
    "len(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2170620"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2170726\n",
    "2170726/180885\n",
    "180885*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01240331, 0.9875967 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dxcup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
